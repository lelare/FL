{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install -q flwr[simulation] torch torchvision matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install alibi-detect[torch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import flwr as fl\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from functools import partial\n",
    "from alibi_detect.cd import MMDDrift\n",
    "from alibi_detect.cd.pytorch import preprocess_drift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set random seed and device\n",
    "seed = 0\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clients = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and preprocess CIFAR-10 dataset\n",
    "(all_x_train, all_y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "all_x_train, x_test = all_x_train / 255.0, x_test / 255.0 \n",
    "all_x_train = all_x_train.astype('float32') / 255\n",
    "x_test = x_test.astype('float32') / 255\n",
    "all_y_train = all_y_train.astype('int64').reshape(-1,)\n",
    "y_test = y_test.astype('int64').reshape(-1,)\n",
    "\n",
    "x_train = all_x_train[0:int(len(all_x_train)*0.8)]\n",
    "y_train = all_y_train[0:int(len(all_y_train)*0.8)]\n",
    "\n",
    "x_val = all_x_train[int(len(all_x_train)*0.8):]\n",
    "y_val = all_y_train[int(len(all_y_train)*0.8):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40000"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate federated clients (splitting the dataset)\n",
    "client_data = []\n",
    "\n",
    "for i in range(n_clients):\n",
    "    start = i * len(x_train) // n_clients\n",
    "    end = (i + 1) * len(x_train) // n_clients\n",
    "    client_data.append((x_train[start:end], y_train[start:end]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20000"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(client_data[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a global model (we had CNN in Task1/2 (class Net))\n",
    "\n",
    "encoding_dim = 32\n",
    "# define encoder\n",
    "global_model = nn.Sequential(\n",
    "    nn.Conv2d(3, 64, 4, stride=2, padding=0),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(64, 128, 4, stride=2, padding=0),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(128, 512, 4, stride=2, padding=0),\n",
    "    nn.ReLU(),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(2048, encoding_dim)\n",
    ").to(device).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def permute_c(x):\n",
    "    return np.transpose(x.astype(np.float32), (0, 3, 1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MMD detector on each client\n",
    "client_detectors = []\n",
    "for x_data, _ in client_data:\n",
    "    \n",
    "    # define preprocessing function\n",
    "    preprocess_fn = partial(preprocess_drift, model=global_model, device=device, batch_size=512)\n",
    "\n",
    "    X_ref = permute_c(x_data[0:200])\n",
    "    # initialise drift detector\n",
    "    detector = MMDDrift(X_ref, backend='pytorch', p_val=.05, \n",
    "                preprocess_fn=preprocess_fn, n_permutations=100)\n",
    "    client_detectors.append(detector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model train\n",
    "def train(x_data, y_data, local_model, num_epochs=5):\n",
    "    \"\"\"Train the network on the training set.\"\"\"\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(local_model.parameters())\n",
    "    local_model.train() \n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_loss = 0.0\n",
    "        for inputs, labels in zip(x_data, y_data):\n",
    "            inputs, labels = torch.from_numpy(inputs).to(device), torch.from_numpy(labels).to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = local_model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # Metrics\n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "        print(f'Epoch {epoch + 1}, Loss: {epoch_loss / len(x_data)}')\n",
    "\n",
    "    return local_model\n",
    "\n",
    "# Moddel test\n",
    "def test(x_data, y_data, local_model):\n",
    "    \"\"\"Evaluate the network on the entire test set.\"\"\"\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    correct, total, loss = 0, 0, 0.0\n",
    "    local_model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in zip(x_data, y_data):\n",
    "            inputs, labels = torch.from_numpy(inputs).to(device), torch.from_numpy(labels).to(device)\n",
    "            outputs = local_model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    loss /= len(x_data)\n",
    "    accuracy = correct / total\n",
    "\n",
    "    return loss, accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drift detection on client data\n",
    "def handle_client_drift(x_data, detector):\n",
    "    is_drift, metrics = detector.predict(permute_c(x_data))\n",
    "    if is_drift:\n",
    "        print(\"Drift detected on client data.\")\n",
    "        # local_model = train(x_data, y_data, local_model, num_epochs=5)\n",
    "    else:\n",
    "        print(\"No drift detected on client data. Continuing training.\")\n",
    "\n",
    "\n",
    "# Drift detection on aggregated data\n",
    "def handle_global_drift(aggregated_data, detector):\n",
    "    is_drift, metrics = detector.predict(permute_c(aggregated_data))\n",
    "    print(metrics) # I think we can get p-value from metrics\n",
    "    if is_drift:\n",
    "        print(\"Drift detected on aggregated data. Updating global model.\")\n",
    "        # Q?: Should I update the global model here?\n",
    "    else:\n",
    "        print(\"No drift detected on aggregated data. Continuing training.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlowerClient(fl.client.NumPyClient):\n",
    "    def __init__(self, client_data, local_model, client_detector):\n",
    "        self.client_data = client_data\n",
    "        self.local_model = local_model\n",
    "        self.client_detector = client_detector\n",
    "\n",
    "    def get_parameters(self):\n",
    "        # Return the current model parameters\n",
    "        return self.local_model.state_dict()\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        # Train the local model after updating it with the given parameters\n",
    "        self.local_model.load_state_dict(parameters)\n",
    "        self.local_model = train(self.client_data[0], self.client_data[1], self.local_model, num_epochs=5)\n",
    "        # Perform local training with client_data and drift detection\n",
    "        handle_client_drift(self.client_data[0], self.client_detector, self.local_model)\n",
    "\n",
    "    def evaluate(self, parameters, config):\n",
    "        # Perform the evaluation of the model after updating it with the given\n",
    "        # parameters. Returns the loss as a float, the length of the validation\n",
    "        # data, and a dict containing the accuracy\n",
    "        self.local_model.load_state_dict(parameters)\n",
    "        loss, accuracy = test(x_val, y_val, self.local_model)\n",
    "        # Q?: Can I run handle_global_drift here instead of test?\n",
    "        # Q?: Do I need test in general?\n",
    "        return float(loss), len(self.valloader), {\"accuracy\": float(accuracy)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def client_fn(cid: str, client_data=client_data) -> FlowerClient:\n",
    "    for x_data, y_data in client_data:\n",
    "        # Apply drift detection on client data\n",
    "        handle_client_drift(x_data, client_detectors[int(cid)])\n",
    "        \n",
    "        local_model = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 4, stride=2, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 128, 4, stride=2, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 512, 4, stride=2, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(2048, encoding_dim)\n",
    "        ).to(device)\n",
    "\n",
    "        # Train the local model\n",
    "        local_model = train(x_data, y_data, local_model, num_epochs=5)\n",
    "        \n",
    "        return FlowerClient(local_model, train_data=(x_data, y_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify client resources if you need GPU (defaults to 1 CPU and 0 GPU)\n",
    "client_resources = None\n",
    "if device.type == \"cuda\":\n",
    "    client_resources = {\"num_gpus\": 1, \"num_cpus\": 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_gpus': 1, 'num_cpus': 1}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client_resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svmem(total=8181506048, available=1757716480, percent=78.5, used=6061858816, free=1540182016, active=750329856, inactive=5608075264, buffers=4460544, cached=575004672, shared=88162304, slab=145850368)\n"
     ]
    }
   ],
   "source": [
    "import psutil\n",
    "\n",
    "print(psutil.virtual_memory())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create FedAvg strategy\n",
    "strategy = fl.server.strategy.FedAvg(\n",
    "    fraction_fit=1.0,          # Sample 100% of available clients for training\n",
    "    fraction_evaluate=0.5,     # Sample 50% of available clients for evaluation\n",
    "    min_fit_clients=2,        # Never sample less than 10 clients for training\n",
    "    min_evaluate_clients=2,    # Never sample less than 5 clients for evaluation\n",
    "    min_available_clients=10,  # Wait until all 10 clients are available\n",
    "    evaluate_metrics_aggregation_fn=handle_global_drift\n",
    "    # Q?: should I call handle_global_drift here?\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flwr 2023-12-14 18:32:35,301 | app.py:175 | Starting Flower simulation, config: ServerConfig(num_rounds=5, round_timeout=None)\n",
      "2023-12-14 18:32:39,725\tINFO worker.py:1621 -- Started a local Ray instance.\n",
      "INFO flwr 2023-12-14 18:32:40,932 | app.py:210 | Flower VCE: Ray initialized with resources: {'CPU': 8.0, 'node:__internal_head__': 1.0, 'memory': 1511025870.0, 'node:172.31.89.100': 1.0, 'object_store_memory': 755512934.0}\n",
      "INFO flwr 2023-12-14 18:32:40,933 | app.py:224 | Flower VCE: Resources for each Virtual Client: {'num_gpus': 1, 'num_cpus': 1}\n",
      "WARNING flwr 2023-12-14 18:32:40,935 | ray_actor.py:132 | The ActorPool is empty. The system (CPUs=8.0, GPUs=0) does not meet the criteria to host at least one client with resources: {'num_gpus': 1, 'num_cpus': 1}. Lowering the `client_resources` could help.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "ActorPool is empty. Stopping Simulation. Check 'client_resources' passed to `start_simulation`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[68], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Start simulation\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mfl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msimulation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart_simulation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_clients\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_clients\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mserver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mServerConfig\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstrategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient_resources\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient_resources\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/flwr/simulation/app.py:242\u001b[0m, in \u001b[0;36mstart_simulation\u001b[0;34m(client_fn, num_clients, clients_ids, client_resources, server, config, strategy, client_manager, ray_init_args, keep_initialised, actor_type, actor_kwargs, actor_scheduling)\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m actor_type\u001b[38;5;241m.\u001b[39moptions(  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    237\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mclient_resources,\n\u001b[1;32m    238\u001b[0m         scheduling_strategy\u001b[38;5;241m=\u001b[39mactor_scheduling,\n\u001b[1;32m    239\u001b[0m     )\u001b[38;5;241m.\u001b[39mremote(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mactor_args)\n\u001b[1;32m    241\u001b[0m \u001b[38;5;66;03m# Instantiate ActorPool\u001b[39;00m\n\u001b[0;32m--> 242\u001b[0m pool \u001b[38;5;241m=\u001b[39m \u001b[43mVirtualClientEngineActorPool\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    243\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_actor_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcreate_actor_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    244\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient_resources\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient_resources\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    245\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    247\u001b[0m f_stop \u001b[38;5;241m=\u001b[39m threading\u001b[38;5;241m.\u001b[39mEvent()\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# Periodically, check if the cluster has grown (i.e. a new\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# node has been added). If this happens, we likely want to grow\u001b[39;00m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;66;03m# the actor pool by adding more Actors to it.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/flwr/simulation/ray_transport/ray_actor.py:184\u001b[0m, in \u001b[0;36mVirtualClientEngineActorPool.__init__\u001b[0;34m(self, create_actor_fn, client_resources, actor_list)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_actor_fn \u001b[38;5;241m=\u001b[39m create_actor_fn\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m actor_list \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;66;03m# Figure out how many actors can be created given the cluster resources\u001b[39;00m\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;66;03m# and the resources the user indicates each VirtualClient will need\u001b[39;00m\n\u001b[0;32m--> 184\u001b[0m     num_actors \u001b[38;5;241m=\u001b[39m \u001b[43mpool_size_from_resources\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclient_resources\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    185\u001b[0m     actors \u001b[38;5;241m=\u001b[39m [create_actor_fn() \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_actors)]\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;66;03m# When __reduce__ is executed, we don't want to created\u001b[39;00m\n\u001b[1;32m    188\u001b[0m     \u001b[38;5;66;03m# a new list of actors again.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/flwr/simulation/ray_transport/ray_actor.py:141\u001b[0m, in \u001b[0;36mpool_size_from_resources\u001b[0;34m(client_resources)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m total_num_actors \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    132\u001b[0m     log(\n\u001b[1;32m    133\u001b[0m         WARNING,\n\u001b[1;32m    134\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe ActorPool is empty. The system (CPUs=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m, GPUs=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    139\u001b[0m         client_resources,\n\u001b[1;32m    140\u001b[0m     )\n\u001b[0;32m--> 141\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    142\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mActorPool is empty. Stopping Simulation. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    143\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCheck \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclient_resources\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m passed to `start_simulation`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    144\u001b[0m     )\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m total_num_actors\n",
      "\u001b[0;31mValueError\u001b[0m: ActorPool is empty. Stopping Simulation. Check 'client_resources' passed to `start_simulation`"
     ]
    }
   ],
   "source": [
    "# Start simulation\n",
    "fl.simulation.start_simulation(\n",
    "    client_fn=client_fn,\n",
    "    num_clients=n_clients,\n",
    "    config=fl.server.ServerConfig(num_rounds=5),\n",
    "    strategy=strategy,\n",
    "    client_resources=client_resources,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
