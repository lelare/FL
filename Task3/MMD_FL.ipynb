{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sBZ7rI13W-BC",
        "outputId": "35b8cb76-5d73-4f70-cb78-6bf741c83bb6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m219.2/219.2 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m42.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.9/56.9 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q flwr[simulation] torch torchvision matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k1MifzRDW-BE",
        "outputId": "b5b99f38-f20b-4d4f-dfbf-d49d1209efc3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting alibi-detect[torch]\n",
            "  Downloading alibi_detect-0.11.4-py3-none-any.whl (372 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m372.4/372.4 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib<4.0.0,>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from alibi-detect[torch]) (3.7.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.16.2 in /usr/local/lib/python3.10/dist-packages (from alibi-detect[torch]) (1.23.5)\n",
            "Requirement already satisfied: pandas<3.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from alibi-detect[torch]) (1.5.3)\n",
            "Requirement already satisfied: Pillow<10.0.0,>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from alibi-detect[torch]) (9.4.0)\n",
            "Requirement already satisfied: opencv-python<5.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from alibi-detect[torch]) (4.8.0.76)\n",
            "Requirement already satisfied: scipy<2.0.0,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from alibi-detect[torch]) (1.11.4)\n",
            "Requirement already satisfied: scikit-image!=0.17.1,<0.22,>=0.14.2 in /usr/local/lib/python3.10/dist-packages (from alibi-detect[torch]) (0.19.3)\n",
            "Requirement already satisfied: scikit-learn<2.0.0,>=0.20.2 in /usr/local/lib/python3.10/dist-packages (from alibi-detect[torch]) (1.2.2)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from alibi-detect[torch]) (4.35.2)\n",
            "Collecting dill<0.4.0,>=0.3.0 (from alibi-detect[torch])\n",
            "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm<5.0.0,>=4.28.1 in /usr/local/lib/python3.10/dist-packages (from alibi-detect[torch]) (4.66.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from alibi-detect[torch]) (2.31.0)\n",
            "Requirement already satisfied: pydantic<2.0.0,>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from alibi-detect[torch]) (1.10.13)\n",
            "Requirement already satisfied: toml<1.0.0,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from alibi-detect[torch]) (0.10.2)\n",
            "Requirement already satisfied: catalogue<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from alibi-detect[torch]) (2.0.10)\n",
            "Collecting numba!=0.54.0,<0.58.0,>=0.50.0 (from alibi-detect[torch])\n",
            "  Downloading numba-0.57.1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m31.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from alibi-detect[torch]) (4.5.0)\n",
            "Collecting torch<1.14.0,>=1.7.0 (from alibi-detect[torch])\n",
            "  Downloading torch-1.13.1-cp310-cp310-manylinux1_x86_64.whl (887.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m887.5/887.5 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4.0.0,>=3.0.0->alibi-detect[torch]) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4.0.0,>=3.0.0->alibi-detect[torch]) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4.0.0,>=3.0.0->alibi-detect[torch]) (4.47.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4.0.0,>=3.0.0->alibi-detect[torch]) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4.0.0,>=3.0.0->alibi-detect[torch]) (23.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4.0.0,>=3.0.0->alibi-detect[torch]) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4.0.0,>=3.0.0->alibi-detect[torch]) (2.8.2)\n",
            "Collecting llvmlite<0.41,>=0.40.0dev0 (from numba!=0.54.0,<0.58.0,>=0.50.0->alibi-detect[torch])\n",
            "  Downloading llvmlite-0.40.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (42.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.1/42.1 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0.0,>=1.0.0->alibi-detect[torch]) (2023.3.post1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.21.0->alibi-detect[torch]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.21.0->alibi-detect[torch]) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.21.0->alibi-detect[torch]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.21.0->alibi-detect[torch]) (2023.11.17)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image!=0.17.1,<0.22,>=0.14.2->alibi-detect[torch]) (3.2.1)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image!=0.17.1,<0.22,>=0.14.2->alibi-detect[torch]) (2.31.6)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image!=0.17.1,<0.22,>=0.14.2->alibi-detect[torch]) (2023.12.9)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image!=0.17.1,<0.22,>=0.14.2->alibi-detect[torch]) (1.5.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<2.0.0,>=0.20.2->alibi-detect[torch]) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<2.0.0,>=0.20.2->alibi-detect[torch]) (3.2.0)\n",
            "Collecting nvidia-cuda-runtime-cu11==11.7.99 (from torch<1.14.0,>=1.7.0->alibi-detect[torch])\n",
            "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m71.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96 (from torch<1.14.0,>=1.7.0->alibi-detect[torch])\n",
            "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66 (from torch<1.14.0,>=1.7.0->alibi-detect[torch])\n",
            "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch<1.14.0,>=1.7.0->alibi-detect[torch])\n",
            "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m71.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch<1.14.0,>=1.7.0->alibi-detect[torch]) (67.7.2)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch<1.14.0,>=1.7.0->alibi-detect[torch]) (0.42.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.0.0->alibi-detect[torch]) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.0.0->alibi-detect[torch]) (0.20.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.0.0->alibi-detect[torch]) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.0.0->alibi-detect[torch]) (2023.6.3)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.0.0->alibi-detect[torch]) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.0.0->alibi-detect[torch]) (0.4.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers<5.0.0,>=4.0.0->alibi-detect[torch]) (2023.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib<4.0.0,>=3.0.0->alibi-detect[torch]) (1.16.0)\n",
            "Installing collected packages: nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cublas-cu11, llvmlite, dill, nvidia-cudnn-cu11, numba, torch, alibi-detect\n",
            "  Attempting uninstall: llvmlite\n",
            "    Found existing installation: llvmlite 0.41.1\n",
            "    Uninstalling llvmlite-0.41.1:\n",
            "      Successfully uninstalled llvmlite-0.41.1\n",
            "  Attempting uninstall: numba\n",
            "    Found existing installation: numba 0.58.1\n",
            "    Uninstalling numba-0.58.1:\n",
            "      Successfully uninstalled numba-0.58.1\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.1.0+cu121\n",
            "    Uninstalling torch-2.1.0+cu121:\n",
            "      Successfully uninstalled torch-2.1.0+cu121\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.1.0+cu121 requires torch==2.1.0, but you have torch 1.13.1 which is incompatible.\n",
            "torchdata 0.7.0 requires torch==2.1.0, but you have torch 1.13.1 which is incompatible.\n",
            "torchtext 0.16.0 requires torch==2.1.0, but you have torch 1.13.1 which is incompatible.\n",
            "torchvision 0.16.0+cu121 requires torch==2.1.0, but you have torch 1.13.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed alibi-detect-0.11.4 dill-0.3.7 llvmlite-0.40.1 numba-0.57.1 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 torch-1.13.1\n"
          ]
        }
      ],
      "source": [
        "!pip install alibi-detect[torch]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "sYB3meL3W-BF"
      },
      "outputs": [],
      "source": [
        "import flwr as fl\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "from functools import partial\n",
        "from alibi_detect.cd import MMDDrift\n",
        "from alibi_detect.cd.pytorch import preprocess_drift\n",
        "\n",
        "import random\n",
        "# import torchvision.datasets as datasets\n",
        "# import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, random_split, Subset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "_cFzV8r5W-BF"
      },
      "outputs": [],
      "source": [
        "# set random seed and device\n",
        "seed = 0\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y52PLlBXW-BG",
        "outputId": "83645ab9-cf6f-4cb5-d2ea-54630485901c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "5kXLb2KjW-BG"
      },
      "outputs": [],
      "source": [
        "n_clients = 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "zgAAWlH2W-BI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "720efb8b-f44b-4dca-fbbb-46b92c863131"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 14s 0us/step\n"
          ]
        }
      ],
      "source": [
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "x_train = x_train.astype(\"float32\") / 255\n",
        "x_test = x_test.astype(\"float32\") / 255\n",
        "y_train = y_train.astype(\"int64\").reshape(\n",
        "    -1,\n",
        ")\n",
        "y_test = y_test.astype(\"int64\").reshape(\n",
        "    -1,\n",
        ")\n",
        "\n",
        "x_train = x_train[0 : int(len(x_train) * 0.2)]\n",
        "y_train = y_train[0 : int(len(y_train) * 0.2)] # just to get some small part of data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "j2y6rLMBW-BJ"
      },
      "outputs": [],
      "source": [
        "# Simulate federated clients (splitting the dataset)\n",
        "client_data = []\n",
        "\n",
        "for i in range(n_clients):\n",
        "    start = i * len(x_train) // n_clients\n",
        "    end = (i + 1) * len(x_train) // n_clients\n",
        "    client_data.append((x_train[start:end], y_train[start:end]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bTARuobiW-BJ",
        "outputId": "1211d340-78bc-4fca-8418-f97d4593f2f0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5000"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "len(client_data[0][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "ErIW6oPOW-BJ"
      },
      "outputs": [],
      "source": [
        "# # Define a global model (we had CNN in Task1/2 (class Net))\n",
        "\n",
        "# encoding_dim = 32\n",
        "# # define encoder\n",
        "# global_model = nn.Sequential(\n",
        "#     nn.Conv2d(3, 64, 4, stride=2, padding=0),\n",
        "#     nn.ReLU(),\n",
        "#     nn.Conv2d(64, 128, 4, stride=2, padding=0),\n",
        "#     nn.ReLU(),\n",
        "#     nn.Conv2d(128, 512, 4, stride=2, padding=0),\n",
        "#     nn.ReLU(),\n",
        "#     nn.Flatten(),\n",
        "#     nn.Linear(2048, encoding_dim)\n",
        "# ).to(device).eval()\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, encoding_dim):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, 4, stride=2, padding=0),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, 128, 4, stride=2, padding=0),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(128, 512, 4, stride=2, padding=0),\n",
        "            nn.ReLU(),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(2048, encoding_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.encoder(x)\n",
        "\n",
        "# Define the encoding dimension\n",
        "encoding_dim = 32\n",
        "\n",
        "# Instantiate the Encoder model\n",
        "encoder_model = Encoder(encoding_dim).to(device).eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "zKePRmZtW-BJ"
      },
      "outputs": [],
      "source": [
        "def permute_c(x):\n",
        "    return np.transpose(x.astype(np.float32), (0, 3, 1, 2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "q3i9xgGpW-BJ"
      },
      "outputs": [],
      "source": [
        "# MMD detector on each client\n",
        "client_detectors = []\n",
        "for x_data, _ in client_data:\n",
        "    # define preprocessing function\n",
        "    preprocess_fn = partial(\n",
        "        preprocess_drift, model=encoder_model, device=device, batch_size=512\n",
        "    )\n",
        "\n",
        "    X_ref = permute_c(x_data[0:200])\n",
        "    # initialise drift detector\n",
        "    detector = MMDDrift(\n",
        "        X_ref,\n",
        "        backend=\"pytorch\",\n",
        "        p_val=0.05,\n",
        "        preprocess_fn=preprocess_fn,\n",
        "        n_permutations=100,\n",
        "    )\n",
        "    client_detectors.append(detector)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "D8TtWOBBW-BK"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "R6vHNwT4W-BK"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "67gkpYQQW-BK"
      },
      "outputs": [],
      "source": [
        "def train(model, x_train, y_train, num_epochs=5):\n",
        "    \"\"\"Train the network on the training set.\"\"\"\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters())\n",
        "    model.train()\n",
        "\n",
        "    train_dataset = TensorDataset(torch.tensor(x_train), torch.tensor(y_train))\n",
        "    trainloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        correct, total, epoch_loss = 0, 0, 0.0\n",
        "        for images, labels in trainloader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            # Metrics\n",
        "            epoch_loss += loss.item()\n",
        "            total += labels.size(0)\n",
        "            correct += (torch.max(outputs.data, 1)[1] == labels).sum().item()\n",
        "        epoch_loss /= len(trainloader.dataset)\n",
        "        epoch_acc = correct / total\n",
        "\n",
        "        print(f\"Epoch {epoch+1}: train loss {epoch_loss}, accuracy {epoch_acc}\")\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def test(model, x_test, y_test):\n",
        "    \"\"\"Evaluate the network on the entire test set.\"\"\"\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    correct, total, loss = 0, 0, 0.0\n",
        "    model.eval()\n",
        "\n",
        "    test_dataset = TensorDataset(torch.tensor(x_test), torch.tensor(y_test))\n",
        "    testloader = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in testloader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            loss += criterion(outputs, labels).item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    loss /= len(testloader.dataset)\n",
        "    print('total', total)\n",
        "    accuracy = correct / total\n",
        "    return loss, accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "EAR8Tc9wW-BK"
      },
      "outputs": [],
      "source": [
        "# Drift detection on client data\n",
        "def handle_client_drift(c_data, detector, net):\n",
        "    (x_train, y_train, x_val, y_val, cid) = c_data\n",
        "\n",
        "    detector_data = detector.predict(x_train, return_p_val=True, return_distance=True)\n",
        "    is_drift = detector_data['data'].get('is_drift', None)\n",
        "    p_val = detector_data['data'].get('p_val', None)\n",
        "    distance = detector_data['data'].get('distance', None)\n",
        "\n",
        "    print(\"Client:\",cid)\n",
        "    print(\"p_val:\",p_val)\n",
        "    print(\"distance:\",distance)\n",
        "\n",
        "    if is_drift:\n",
        "        print(\"Drift detected on client data. Retraining local model.\")\n",
        "        net = train(net, x_train, y_train, num_epochs=5)\n",
        "    else:\n",
        "        print(\"No drift detected on client data. Continuing training.\")\n",
        "    return net\n",
        "\n",
        "\n",
        "# Drift detection on aggregated data\n",
        "def handle_global_drift(aggregated_data, detector, global_model):\n",
        "    is_drift, metrics = detector.predict(permute_c(aggregated_data[\"x_train\"]))\n",
        "    print(metrics)  # You may extract useful information, e.g., p-value, from metrics\n",
        "    if is_drift:\n",
        "        print(\"Drift detected on aggregated data. Updating global model.\")\n",
        "        # Update the global model based on aggregated_data\n",
        "        # global_model = train(\n",
        "        #     global_model,\n",
        "        #     aggregated_data[\"x_train\"],\n",
        "        #     aggregated_data[\"y_train\"],\n",
        "        #     num_epochs=5,\n",
        "        # )\n",
        "    else:\n",
        "        print(\"No drift detected on aggregated data. Continuing training.\")\n",
        "    # return global_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "E-qicpdBW-BK"
      },
      "outputs": [],
      "source": [
        "class FlowerClient(fl.client.NumPyClient):\n",
        "    def __init__(self, client_data, model):\n",
        "        self.client_data = client_data\n",
        "        self.model = model\n",
        "\n",
        "    def get_parameters(self, config):\n",
        "        # Return the current model parameters\n",
        "        return [param.detach().cpu().numpy() for param in self.model.parameters()]\n",
        "\n",
        "    def fit(self, parameters, config):\n",
        "        # Train the local model after updating it with the given parameters\n",
        "        # Convert parameters from numpy arrays to torch tensors\n",
        "        state_dict = {\n",
        "            key: torch.from_numpy(param)\n",
        "            for key, param in zip(self.model.state_dict(), parameters)\n",
        "        }\n",
        "        self.model.load_state_dict(state_dict)\n",
        "\n",
        "        # Perform local training with client_data and drift detection\n",
        "        # self.model = handle_client_drift(\n",
        "        #     self.client_data, self.client_detector, self.model\n",
        "        # )\n",
        "        # handle_client_drift(self.client_data, self.client_detector, self.model) ## Q?: Do I need handle_client_drift here?\n",
        "        new_params = [param.detach().cpu().numpy() for param in self.model.parameters()]\n",
        "        return new_params, len(self.client_data[\"x_train\"]), {}\n",
        "\n",
        "    def evaluate(self, parameters, config):\n",
        "        # Perform the evaluation of the model after updating it with the given\n",
        "        # parameters. Returns the loss as a float, the length of the validation\n",
        "        # data, and a dict containing the accuracy\n",
        "        # Convert parameters from numpy arrays to torch tensors\n",
        "        state_dict = {\n",
        "            key: torch.from_numpy(param)\n",
        "            for key, param in zip(self.model.state_dict(), parameters)\n",
        "        }\n",
        "        self.model.load_state_dict(state_dict)\n",
        "        # Perform evaluation\n",
        "        loss, accuracy = test(\n",
        "            self.model, self.client_data[\"x_val\"], self.client_data[\"y_val\"]\n",
        "        )\n",
        "\n",
        "        return (\n",
        "            float(loss),\n",
        "            len(self.client_data[\"y_val\"]),\n",
        "            {\"accuracy\": float(accuracy)},\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "dpNwTm24W-BL"
      },
      "outputs": [],
      "source": [
        "def client_fn(cid: str, client_data=client_data) -> FlowerClient:\n",
        "        x_data, y_data = client_data[int(cid)]\n",
        "        # x_data = np.array(x_data)\n",
        "        x_data = permute_c(x_data)\n",
        "        # y_data = np.array(y_data)\n",
        "\n",
        "        x_train = x_data[0 : int(len(x_data) * 0.8)]\n",
        "        y_train = y_data[0 : int(len(y_data) * 0.8)]\n",
        "\n",
        "        x_val = x_data[int(len(x_data) * 0.8) :]\n",
        "        y_val = y_data[int(len(y_data) * 0.8) :]\n",
        "\n",
        "        all_data = []\n",
        "        all_data.extend((x_train, y_train, x_val, y_val, int(cid)))\n",
        "        # Apply drift detection on client data\n",
        "\n",
        "        model = Encoder(encoding_dim).to(device)\n",
        "\n",
        "        # model = handle_client_drift(all_data, client_detectors[int(cid)], model)\n",
        "        handle_client_drift(all_data, client_detectors[int(cid)], model)\n",
        "\n",
        "        # Train the local model\n",
        "        train(\n",
        "            model,\n",
        "            x_train,\n",
        "            y_train,\n",
        "            num_epochs=5,\n",
        "        )\n",
        "\n",
        "        return FlowerClient(client_data={\"x_train\": x_train, \"y_train\": y_train, \"x_val\": x_val, \"y_val\": y_val}, model=model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "zq9eTFFvW-BL"
      },
      "outputs": [],
      "source": [
        "# Specify client resources if you need GPU (defaults to 1 CPU and 0 GPU)\n",
        "client_resources = None\n",
        "if device.type == \"cuda\":\n",
        "    client_resources = {\"num_gpus\": 1, \"num_cpus\": 1}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mCfn90IfW-BL",
        "outputId": "d2452ae1-b1c9-40db-e9cb-d0762825821c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'num_gpus': 1, 'num_cpus': 1}"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "client_resources"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "9ndaUXgXW-BM"
      },
      "outputs": [],
      "source": [
        "# Create FedAvg strategy\n",
        "strategy = fl.server.strategy.FedAvg(\n",
        "    fraction_fit=1.0,          # Sample 100% of available clients for training\n",
        "    fraction_evaluate=0.5,     # Sample 50% of available clients for evaluation\n",
        "    min_fit_clients=2,        # Never sample less than 10 clients for training\n",
        "    min_evaluate_clients=2,    # Never sample less than 5 clients for evaluation\n",
        "    min_available_clients=2,  # Wait until all 10 clients are available\n",
        "    # evaluate_metrics_aggregation_fn=handle_global_drift\n",
        "    # Q?: should I call handle_global_drift here?\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BtPsIvaBW-BM",
        "outputId": "b3d6481f-b83e-4b28-d050-6614dada4c0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO flwr 2024-01-22 02:37:17,876 | app.py:178 | Starting Flower simulation, config: ServerConfig(num_rounds=2, round_timeout=None)\n",
            "INFO:flwr:Starting Flower simulation, config: ServerConfig(num_rounds=2, round_timeout=None)\n",
            "2024-01-22 02:37:22,604\tINFO worker.py:1621 -- Started a local Ray instance.\n",
            "INFO flwr 2024-01-22 02:37:24,849 | app.py:213 | Flower VCE: Ray initialized with resources: {'memory': 7912058880.0, 'object_store_memory': 3956029440.0, 'GPU': 1.0, 'node:172.28.0.12': 1.0, 'node:__internal_head__': 1.0, 'CPU': 8.0}\n",
            "INFO:flwr:Flower VCE: Ray initialized with resources: {'memory': 7912058880.0, 'object_store_memory': 3956029440.0, 'GPU': 1.0, 'node:172.28.0.12': 1.0, 'node:__internal_head__': 1.0, 'CPU': 8.0}\n",
            "INFO flwr 2024-01-22 02:37:24,858 | app.py:219 | Optimize your simulation with Flower VCE: https://flower.dev/docs/framework/how-to-run-simulations.html\n",
            "INFO:flwr:Optimize your simulation with Flower VCE: https://flower.dev/docs/framework/how-to-run-simulations.html\n",
            "INFO flwr 2024-01-22 02:37:24,866 | app.py:242 | Flower VCE: Resources for each Virtual Client: {'num_gpus': 1, 'num_cpus': 1}\n",
            "INFO:flwr:Flower VCE: Resources for each Virtual Client: {'num_gpus': 1, 'num_cpus': 1}\n",
            "INFO flwr 2024-01-22 02:37:24,898 | app.py:288 | Flower VCE: Creating VirtualClientEngineActorPool with 1 actors\n",
            "INFO:flwr:Flower VCE: Creating VirtualClientEngineActorPool with 1 actors\n",
            "INFO flwr 2024-01-22 02:37:24,900 | server.py:89 | Initializing global parameters\n",
            "INFO:flwr:Initializing global parameters\n",
            "INFO flwr 2024-01-22 02:37:24,903 | server.py:276 | Requesting initial parameters from one random client\n",
            "INFO:flwr:Requesting initial parameters from one random client\n",
            "\u001b[2m\u001b[36m(pid=2837)\u001b[0m 2024-01-22 02:37:26.416135: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[2m\u001b[36m(pid=2837)\u001b[0m 2024-01-22 02:37:26.416218: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[2m\u001b[36m(pid=2837)\u001b[0m 2024-01-22 02:37:26.417668: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[2m\u001b[36m(pid=2837)\u001b[0m 2024-01-22 02:37:27.575132: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2837)\u001b[0m /usr/local/lib/python3.10/dist-packages/alibi_detect/cd/pytorch/mmd.py:127: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:199.)\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2837)\u001b[0m   x_ref = torch.from_numpy(x_ref).to(self.device)  # type: ignore[assignment]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(DefaultActor pid=2837)\u001b[0m Client: 0\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2837)\u001b[0m p_val: 0.6499999761581421\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2837)\u001b[0m distance: -0.00043576955795288086\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2837)\u001b[0m No drift detected on client data. Continuing training.\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2837)\u001b[0m Epoch 1: train loss 0.06696390679478645, accuracy 0.20325\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2837)\u001b[0m Epoch 2: train loss 0.054985032618045805, accuracy 0.3595\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2837)\u001b[0m Epoch 3: train loss 0.04975893148779869, accuracy 0.41925\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2837)\u001b[0m Epoch 4: train loss 0.045352270424366, accuracy 0.4825\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO flwr 2024-01-22 02:37:40,303 | server.py:280 | Received initial parameters from one random client\n",
            "INFO:flwr:Received initial parameters from one random client\n",
            "INFO flwr 2024-01-22 02:37:40,307 | server.py:91 | Evaluating initial parameters\n",
            "INFO:flwr:Evaluating initial parameters\n",
            "INFO flwr 2024-01-22 02:37:40,312 | server.py:104 | FL starting\n",
            "INFO:flwr:FL starting\n",
            "DEBUG flwr 2024-01-22 02:37:40,315 | server.py:222 | fit_round 1: strategy sampled 2 clients (out of 2)\n",
            "DEBUG:flwr:fit_round 1: strategy sampled 2 clients (out of 2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(DefaultActor pid=2837)\u001b[0m Epoch 5: train loss 0.04165339416265488, accuracy 0.524\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2837)\u001b[0m Client: 1\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2837)\u001b[0m p_val: 0.7300000190734863\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2837)\u001b[0m distance: -0.0004488229751586914\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2837)\u001b[0m No drift detected on client data. Continuing training.\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2837)\u001b[0m Epoch 1: train loss 0.06694731310009956, accuracy 0.2105\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2837)\u001b[0m Epoch 2: train loss 0.053859348773956296, accuracy 0.37275\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2837)\u001b[0m Epoch 3: train loss 0.0488228754401207, accuracy 0.43\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2837)\u001b[0m Epoch 4: train loss 0.044787902608513834, accuracy 0.4705\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2837)\u001b[0m Epoch 5: train loss 0.04099466572701931, accuracy 0.5255\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2837)\u001b[0m Client: 0\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2837)\u001b[0m p_val: 0.6899999976158142\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2837)\u001b[0m distance: -0.00043582916259765625\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2837)\u001b[0m No drift detected on client data. Continuing training.\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2837)\u001b[0m Epoch 1: train loss 0.0658678187429905, accuracy 0.229\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2837)\u001b[0m Epoch 2: train loss 0.05374584120512009, accuracy 0.36675\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2837)\u001b[0m Epoch 3: train loss 0.04848965585231781, accuracy 0.43525\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2837)\u001b[0m Epoch 4: train loss 0.04492247286438942, accuracy 0.4845\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2024-01-22 02:37:49,132 | server.py:236 | fit_round 1 received 2 results and 0 failures\n",
            "DEBUG:flwr:fit_round 1 received 2 results and 0 failures\n",
            "WARNING flwr 2024-01-22 02:37:49,157 | fedavg.py:242 | No fit_metrics_aggregation_fn provided\n",
            "WARNING:flwr:No fit_metrics_aggregation_fn provided\n",
            "DEBUG flwr 2024-01-22 02:37:49,161 | server.py:173 | evaluate_round 1: strategy sampled 2 clients (out of 2)\n",
            "DEBUG:flwr:evaluate_round 1: strategy sampled 2 clients (out of 2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(DefaultActor pid=2837)\u001b[0m Epoch 5: train loss 0.04115588167309761, accuracy 0.523\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2837)\u001b[0m Client: 0\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2837)\u001b[0m p_val: 0.6600000262260437\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2837)\u001b[0m distance: -0.00043582916259765625\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2837)\u001b[0m No drift detected on client data. Continuing training.\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2837)\u001b[0m Epoch 1: train loss 0.06789397594332695, accuracy 0.20325\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2837)\u001b[0m Epoch 2: train loss 0.05557058334350586, accuracy 0.351\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2837)\u001b[0m Epoch 3: train loss 0.04987913128733635, accuracy 0.424\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2837)\u001b[0m Epoch 4: train loss 0.046074427783489226, accuracy 0.47125\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2837)\u001b[0m Epoch 5: train loss 0.0420899463146925, accuracy 0.52075\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2837)\u001b[0m total 1000\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2837)\u001b[0m Client: 1\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2837)\u001b[0m p_val: 0.6899999976158142\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2837)\u001b[0m distance: -0.0004488229751586914\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2837)\u001b[0m No drift detected on client data. Continuing training.\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2837)\u001b[0m Epoch 1: train loss 0.06690093928575516, accuracy 0.20325\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2837)\u001b[0m Epoch 2: train loss 0.0549431734085083, accuracy 0.3615\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2837)\u001b[0m Epoch 3: train loss 0.04820143306255341, accuracy 0.43325\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2837)\u001b[0m Epoch 4: train loss 0.04408804991841316, accuracy 0.48675\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2024-01-22 02:37:56,838 | server.py:187 | evaluate_round 1 received 2 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 1 received 2 results and 0 failures\n",
            "WARNING flwr 2024-01-22 02:37:56,842 | fedavg.py:273 | No evaluate_metrics_aggregation_fn provided\n",
            "WARNING:flwr:No evaluate_metrics_aggregation_fn provided\n",
            "DEBUG flwr 2024-01-22 02:37:56,845 | server.py:222 | fit_round 2: strategy sampled 2 clients (out of 2)\n",
            "DEBUG:flwr:fit_round 2: strategy sampled 2 clients (out of 2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(DefaultActor pid=2837)\u001b[0m Epoch 5: train loss 0.0397581602036953, accuracy 0.537\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2837)\u001b[0m total 1000\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2837)\u001b[0m Client: 0\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2837)\u001b[0m p_val: 0.7200000286102295\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2837)\u001b[0m distance: -0.00043582916259765625\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2837)\u001b[0m No drift detected on client data. Continuing training.\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2837)\u001b[0m Epoch 1: train loss 0.0668560910820961, accuracy 0.2125\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2837)\u001b[0m Epoch 2: train loss 0.053809002906084064, accuracy 0.36875\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2837)\u001b[0m Epoch 3: train loss 0.048579350978136066, accuracy 0.42875\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2837)\u001b[0m Epoch 4: train loss 0.044564552903175354, accuracy 0.4835\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2837)\u001b[0m Epoch 5: train loss 0.040556344717741014, accuracy 0.53575\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2837)\u001b[0m Client: 1\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2837)\u001b[0m p_val: 0.6299999952316284\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2837)\u001b[0m distance: -0.0004488229751586914\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2837)\u001b[0m No drift detected on client data. Continuing training.\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2837)\u001b[0m Epoch 1: train loss 0.06822008690237999, accuracy 0.19575\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2837)\u001b[0m Epoch 2: train loss 0.05560726892948151, accuracy 0.344\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2837)\u001b[0m Epoch 3: train loss 0.05015820735692978, accuracy 0.411\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2837)\u001b[0m Epoch 4: train loss 0.046443897515535355, accuracy 0.4595\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2024-01-22 02:38:05,056 | server.py:236 | fit_round 2 received 2 results and 0 failures\n",
            "DEBUG:flwr:fit_round 2 received 2 results and 0 failures\n",
            "DEBUG flwr 2024-01-22 02:38:05,078 | server.py:173 | evaluate_round 2: strategy sampled 2 clients (out of 2)\n",
            "DEBUG:flwr:evaluate_round 2: strategy sampled 2 clients (out of 2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(DefaultActor pid=2837)\u001b[0m Epoch 5: train loss 0.04285445073246956, accuracy 0.498\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2837)\u001b[0m Client: 1\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2837)\u001b[0m p_val: 0.7300000190734863\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2837)\u001b[0m distance: -0.0004488229751586914\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2837)\u001b[0m No drift detected on client data. Continuing training.\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2837)\u001b[0m Epoch 1: train loss 0.06797759488224983, accuracy 0.197\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2837)\u001b[0m Epoch 2: train loss 0.0554268451333046, accuracy 0.349\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2837)\u001b[0m Epoch 3: train loss 0.05070326006412506, accuracy 0.413\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2837)\u001b[0m Epoch 4: train loss 0.04665420040488243, accuracy 0.46125\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2837)\u001b[0m Epoch 5: train loss 0.042946809887886045, accuracy 0.49925\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2837)\u001b[0m total 1000\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2837)\u001b[0m Client: 0\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2837)\u001b[0m p_val: 0.6800000071525574\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2837)\u001b[0m distance: -0.00043582916259765625\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2837)\u001b[0m No drift detected on client data. Continuing training.\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2837)\u001b[0m Epoch 1: train loss 0.06761269736289978, accuracy 0.20325\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2837)\u001b[0m Epoch 2: train loss 0.05584071734547615, accuracy 0.35425\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2837)\u001b[0m Epoch 3: train loss 0.04961938759684563, accuracy 0.42525\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2837)\u001b[0m Epoch 4: train loss 0.04609751474857331, accuracy 0.46175\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2024-01-22 02:38:13,128 | server.py:187 | evaluate_round 2 received 2 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 2 received 2 results and 0 failures\n",
            "INFO flwr 2024-01-22 02:38:13,131 | server.py:153 | FL finished in 32.81657117899999\n",
            "INFO:flwr:FL finished in 32.81657117899999\n",
            "INFO flwr 2024-01-22 02:38:13,136 | app.py:226 | app_fit: losses_distributed [(1, 0.04647466617822647), (2, 0.04647466617822647)]\n",
            "INFO:flwr:app_fit: losses_distributed [(1, 0.04647466617822647), (2, 0.04647466617822647)]\n",
            "INFO flwr 2024-01-22 02:38:13,138 | app.py:227 | app_fit: metrics_distributed_fit {}\n",
            "INFO:flwr:app_fit: metrics_distributed_fit {}\n",
            "INFO flwr 2024-01-22 02:38:13,139 | app.py:228 | app_fit: metrics_distributed {}\n",
            "INFO:flwr:app_fit: metrics_distributed {}\n",
            "INFO flwr 2024-01-22 02:38:13,145 | app.py:229 | app_fit: losses_centralized []\n",
            "INFO:flwr:app_fit: losses_centralized []\n",
            "INFO flwr 2024-01-22 02:38:13,149 | app.py:230 | app_fit: metrics_centralized {}\n",
            "INFO:flwr:app_fit: metrics_centralized {}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(DefaultActor pid=2837)\u001b[0m Epoch 5: train loss 0.042640629991889, accuracy 0.509\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=2837)\u001b[0m total 1000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "History (loss, distributed):\n",
              "\tround 1: 0.04647466617822647\n",
              "\tround 2: 0.04647466617822647"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "# Start simulation\n",
        "fl.simulation.start_simulation(\n",
        "    client_fn=client_fn,\n",
        "    num_clients=n_clients,\n",
        "    config=fl.server.ServerConfig(num_rounds=2),\n",
        "    strategy=strategy,\n",
        "    client_resources=client_resources,\n",
        "    ray_init_args={\"num_cpus\": 8, \"num_gpus\": 1},\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RB7mRMd9x3f3"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}