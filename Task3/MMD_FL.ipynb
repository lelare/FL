{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import flwr as fl\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from functools import partial\n",
    "from alibi_detect.cd import MMDDrift\n",
    "from alibi_detect.cd.pytorch import preprocess_drift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set random seed and device\n",
    "seed = 0\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clients = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and preprocess CIFAR-10 dataset\n",
    "(all_x_train, all_y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "all_x_train, x_test = all_x_train / 255.0, x_test / 255.0 \n",
    "all_x_train = all_x_train.astype('float32') / 255\n",
    "x_test = x_test.astype('float32') / 255\n",
    "all_y_train = all_y_train.astype('int64').reshape(-1,)\n",
    "y_test = y_test.astype('int64').reshape(-1,)\n",
    "\n",
    "x_train = all_x_train[0:int(len(all_x_train)*0.8)]\n",
    "y_train = all_y_train[0:int(len(all_y_train)*0.8)]\n",
    "\n",
    "x_val = all_x_train[int(len(all_x_train)*0.8):]\n",
    "y_val = all_y_train[int(len(all_y_train)*0.8):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate federated clients (splitting the dataset)\n",
    "client_data = []\n",
    "\n",
    "for i in range(n_clients):\n",
    "    start = i * len(x_train) // n_clients\n",
    "    end = (i + 1) * len(x_train) // n_clients\n",
    "    client_data.append((x_train[start:end], y_train[start:end]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(client_data[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a global model (we had CNN in Task1/2 (class Net))\n",
    "\n",
    "encoding_dim = 32\n",
    "# define encoder\n",
    "global_model = nn.Sequential(\n",
    "    nn.Conv2d(3, 64, 4, stride=2, padding=0),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(64, 128, 4, stride=2, padding=0),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(128, 512, 4, stride=2, padding=0),\n",
    "    nn.ReLU(),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(2048, encoding_dim)\n",
    ").to(device).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def permute_c(x):\n",
    "    return np.transpose(x.astype(np.float32), (0, 3, 1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MMD detector on each client\n",
    "client_detectors = []\n",
    "for x_data, _ in client_data:\n",
    "    \n",
    "    # define preprocessing function\n",
    "    preprocess_fn = partial(preprocess_drift, model=global_model, device=device, batch_size=512)\n",
    "\n",
    "    X_ref = permute_c(x_data[0:200])\n",
    "    # initialise drift detector\n",
    "    detector = MMDDrift(X_ref, backend='pytorch', p_val=.05, \n",
    "                preprocess_fn=preprocess_fn, n_permutations=100)\n",
    "    client_detectors.append(detector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model train\n",
    "def train(x_data, y_data, local_model, num_epochs=5):\n",
    "    \"\"\"Train the network on the training set.\"\"\"\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(local_model.parameters())\n",
    "    local_model.train() \n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_loss = 0.0\n",
    "        for inputs, labels in zip(x_data, y_data):\n",
    "            inputs, labels = torch.from_numpy(inputs).to(device), torch.from_numpy(labels).to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = local_model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # Metrics\n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "        print(f'Epoch {epoch + 1}, Loss: {epoch_loss / len(x_data)}')\n",
    "\n",
    "    return local_model\n",
    "\n",
    "# Moddel test\n",
    "def test(x_data, y_data, local_model):\n",
    "    \"\"\"Evaluate the network on the entire test set.\"\"\"\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    correct, total, loss = 0, 0, 0.0\n",
    "    local_model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in zip(x_data, y_data):\n",
    "            inputs, labels = torch.from_numpy(inputs).to(device), torch.from_numpy(labels).to(device)\n",
    "            outputs = local_model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    loss /= len(x_data)\n",
    "    accuracy = correct / total\n",
    "\n",
    "    return loss, accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drift detection on client data\n",
    "def handle_client_drift(x_data, detector):\n",
    "    is_drift, metrics = detector.predict(permute_c(x_data))\n",
    "    if is_drift:\n",
    "        print(\"Drift detected on client data.\")\n",
    "        # local_model = train(x_data, y_data, local_model, num_epochs=5)\n",
    "    else:\n",
    "        print(\"No drift detected on client data. Continuing training.\")\n",
    "\n",
    "\n",
    "# Drift detection on aggregated data\n",
    "def handle_global_drift(aggregated_data, detector):\n",
    "    is_drift, metrics = detector.predict(permute_c(aggregated_data))\n",
    "    print(metrics) # I think we can get p-value from metrics\n",
    "    if is_drift:\n",
    "        print(\"Drift detected on aggregated data. Updating global model.\")\n",
    "        # Should I update the global model here?\n",
    "    else:\n",
    "        print(\"No drift detected on aggregated data. Continuing training.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlowerClient(fl.client.NumPyClient):\n",
    "    def __init__(self, client_data, local_model, client_detector):\n",
    "        self.client_data = client_data\n",
    "        self.local_model = local_model\n",
    "        self.client_detector = client_detector\n",
    "\n",
    "    def get_parameters(self):\n",
    "        # Return the current model parameters\n",
    "        return self.local_model.state_dict()\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        # Train the local model after updating it with the given parameters\n",
    "        self.local_model.load_state_dict(parameters)\n",
    "        self.local_model = train(self.client_data[0], self.client_data[1], self.local_model, num_epochs=5)\n",
    "        # Perform local training with client_data and drift detection\n",
    "        handle_client_drift(self.client_data[0], self.client_detector, self.local_model)\n",
    "\n",
    "    def evaluate(self, parameters, config):\n",
    "        # Perform the evaluation of the model after updating it with the given\n",
    "        # parameters. Returns the loss as a float, the length of the validation\n",
    "        # data, and a dict containing the accuracy\n",
    "        self.local_model.load_state_dict(parameters)\n",
    "        loss, accuracy = test(x_val, y_val, self.local_model)\n",
    "        # Can I run handle_global_drift here instead of test?\n",
    "        return float(loss), len(self.valloader), {\"accuracy\": float(accuracy)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def client_fn(cid: str, client_data=client_data) -> FlowerClient:\n",
    "    for x_data, y_data in client_data:\n",
    "        # Apply drift detection on client data\n",
    "        handle_client_drift(x_data, client_detectors[int(cid)])\n",
    "        \n",
    "        local_model = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 4, stride=2, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 128, 4, stride=2, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 512, 4, stride=2, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(2048, encoding_dim)\n",
    "        ).to(device)\n",
    "\n",
    "        # Train the local model\n",
    "        local_model = train(x_data, y_data, local_model, num_epochs=5)\n",
    "        \n",
    "        return FlowerClient(local_model, train_data=(x_data, y_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify client resources if you need GPU (defaults to 1 CPU and 0 GPU)\n",
    "client_resources = None\n",
    "if device == \"cuda\":\n",
    "    client_resources = {\"num_gpus\": 1, 'num_cpus': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create FedAvg strategy\n",
    "strategy = fl.server.strategy.FedAvg(\n",
    "    fraction_fit=1.0,          # Sample 100% of available clients for training\n",
    "    fraction_evaluate=0.5,     # Sample 50% of available clients for evaluation\n",
    "    min_fit_clients=10,        # Never sample less than 10 clients for training\n",
    "    min_evaluate_clients=5,    # Never sample less than 5 clients for evaluation\n",
    "    min_available_clients=10,  # Wait until all 10 clients are available\n",
    "    evaluate_metrics_aggregation_fn=handle_global_drift\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start simulation\n",
    "fl.simulation.start_simulation(\n",
    "    client_fn=client_fn,\n",
    "    num_clients=n_clients,\n",
    "    config=fl.server.ServerConfig(num_rounds=5),\n",
    "    strategy=strategy,\n",
    "    client_resources=client_resources,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
